{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImagingDataCommons/Cloud-Resources-Workflows/blob/notebooks2/Notebooks/Totalsegmentator/preProccessing_of_postProcessingExtractPerframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qWeL6RS4pVtu",
      "metadata": {
        "id": "qWeL6RS4pVtu"
      },
      "source": [
        "**This notebook provides a step-by-step guide on how to generate a datatable for Terra. This datatable is essential for extracting the DICOM attribute, PerFrameFunctionalGroupsSequence, using the workflow linked below.**\n",
        "\n",
        "You can find the PerFrameFunctionalGroupsSequence Extraction workflow [here](https://dockstore.org/workflows/github.com/ImagingDataCommons/Cloud-Resources-Workflows/perFrameFunctionalGroupSequenceExtractionOnTerra:main?tab=info).\n",
        "\n",
        "The workflow requires manifests as inputs, each of which containining 10 (chosen arbitarily can be any number) batches of compressed DICOM SEGs, amounting to up to 120 DICOM SEG files. These manifests include URLs, accessible by a service account, that point to the compressed DICOM SEG files. These files are generated by the TotalSegmentator workflow on Terra.\n",
        "\n",
        "Once these steps are completed, a datatable is produced and is ready to be uploaded to Terra's data tables, that can be referenced for  PerFrameFunctionalGroupsSequence Extraction workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-LdyuHrrPigD",
      "metadata": {
        "id": "-LdyuHrrPigD"
      },
      "source": [
        "###**Installing Packages (local)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B5KuCCFhOgpA",
      "metadata": {
        "id": "B5KuCCFhOgpA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!sudo apt-get update \\\n",
        "  && apt-get install -y --no-install-recommends \\\n",
        "  lz4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B0TrOX90OhV_",
      "metadata": {
        "id": "B0TrOX90OhV_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pydicom \\\n",
        "   google-cloud-bigquery \\\n",
        "   pyarrow \\\n",
        "   db_dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73LFRISZPn6Q",
      "metadata": {
        "id": "73LFRISZPn6Q"
      },
      "source": [
        "###**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4585bb-9bfb-4de3-882a-c7454c7ec3af",
      "metadata": {
        "id": "db4585bb-9bfb-4de3-882a-c7454c7ec3af"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import traceback\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1mqxvpePhxA",
      "metadata": {
        "id": "d1mqxvpePhxA"
      },
      "source": [
        "###**Example Terra datatable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bri49R5rsPsW",
      "metadata": {
        "id": "Bri49R5rsPsW"
      },
      "outputs": [],
      "source": [
        "segFilesCsv='https://raw.githubusercontent.com/ImagingDataCommons/Cloud-Resources-Workflows/notebooks/sampleManifests/sample_two_vm_workflow_datatable_on_terra.tsv'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fU_QT-Dnsakj",
      "metadata": {
        "id": "fU_QT-Dnsakj"
      },
      "source": [
        "###**Read the tsv from twoVMworkflow datatable on terra**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kgt7OeFzP1BX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "Kgt7OeFzP1BX",
        "outputId": "f108d3fa-87c7-4cc2-a79d-54278ed0f9ef"
      },
      "outputs": [],
      "source": [
        "data= pd.read_table(segFilesCsv)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8hURoGz0wfe7",
      "metadata": {
        "id": "8hURoGz0wfe7"
      },
      "source": [
        "###**Copy the files from Terra bucket to another bucket where you can create service accounts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qVSsZg0q2P4P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "qVSsZg0q2P4P",
        "outputId": "32bee96c-eecf-4aea-fa2b-9d70630b1e80"
      },
      "outputs": [],
      "source": [
        "# Add a new column called 'new_destination'\n",
        "project_id='test_project'\n",
        "bucketname='test_bucket'\n",
        "first_column = data.columns[0]  # Get the label of the first column\n",
        "# Populate the 'new_destination' column with values that are a concatenation of 'bucket_id' and 'batch_id'\n",
        "data['new_destination'] = data[\"dicomsegAndRadiomicsSR_CompressedFiles\"] +' '+f'gs://{bucketname}/' + data[first_column].astype(str)+'/'\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A8fR5Xcl3c-G",
      "metadata": {
        "id": "A8fR5Xcl3c-G"
      },
      "outputs": [],
      "source": [
        "!gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xlvUT07E3jzA",
      "metadata": {
        "id": "xlvUT07E3jzA"
      },
      "outputs": [],
      "source": [
        "!gcloud config set project $project_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SRS2TbP32oUJ",
      "metadata": {
        "id": "SRS2TbP32oUJ"
      },
      "outputs": [],
      "source": [
        "urls= data['new_destination'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Aldc3kZN3xoR",
      "metadata": {
        "id": "Aldc3kZN3xoR"
      },
      "outputs": [],
      "source": [
        "for url in urls:\n",
        "  !gsutil cp {url}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de-zRHR4InP8",
      "metadata": {
        "id": "de-zRHR4InP8"
      },
      "source": [
        "###**Generate manifests for Terra datatable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N0dTxO-P6TQx",
      "metadata": {
        "id": "N0dTxO-P6TQx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data[\"batch_number\"] = data[data.columns[0]].str.extract(\"(\\d+)\").astype(int)\n",
        "data = data.sort_values(\"batch_number\")\n",
        "data = data.drop(columns=[\"batch_number\"])\n",
        "\n",
        "# Create 'urls' directory if it doesn't exist\n",
        "if not os.path.exists(\"urls\"):\n",
        "    os.makedirs(\"urls\")\n",
        "\n",
        "# Split DataFrame into batches of 10 rows each\n",
        "num_batches = len(data) // 10 + (len(data) % 10 > 0)\n",
        "\n",
        "for i in range(num_batches):\n",
        "    batch = data.iloc[i * 10 : (i + 1) * 10]\n",
        "    batch.to_csv(f\"urls/batch_{i+1}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V0q2ejgFmyKT",
      "metadata": {
        "id": "V0q2ejgFmyKT"
      },
      "source": [
        "###**Upload manifests to Terra bucket and Generate Terra datatable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ZdP0SRgKTSD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "5ZdP0SRgKTSD",
        "outputId": "f56faff7-2dc8-40d2-8c2a-c020df5ac7ec"
      },
      "outputs": [],
      "source": [
        "now = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
        "terra_bucket = \"test-terra-bucket\"\n",
        "folder_in_terra_bucket = \"perframe\"\n",
        "\n",
        "entity_column_name = f\"entity:perframe_{now}_id\"\n",
        "\n",
        "# Initialize a list to store each row as a DataFrame\n",
        "rows = []\n",
        "\n",
        "# Iterate over each file in the 'urls' directory\n",
        "for filename in os.listdir(\"urls\"):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        # Extract the batch number from the filename\n",
        "        entity = filename.split(\"_\")[1].split(\".\")[0]\n",
        "\n",
        "        # Construct the GCS URL for this batch's file\n",
        "        gcsurl = os.path.join(terra_bucket, folder_in_terra_bucket, filename)\n",
        "\n",
        "        !gsutil cp filename gcsurl\n",
        "\n",
        "        # Append a new row to the list as a DataFrame\n",
        "        rows.append(pd.DataFrame({entity_column_name: [entity], \"gcsurl\": [gcsurl]}))\n",
        "\n",
        "# Concatenate all the DataFrames in the list\n",
        "terra_df = pd.concat(rows, ignore_index=True)\n",
        "\n",
        "# Save the DataFrame to a .tsv file\n",
        "terra_df = terra_df.sort_values(by=entity_column_name)\n",
        "terra_df.to_csv(\"terra_datatable.tsv\", sep=\"\\t\", index=False)\n",
        "terra_df\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
