{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkt1414/Cloud-Resources-Workflows/blob/main/Notebooks/Totalsegmentator/postProcessingExtractPerframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-LdyuHrrPigD",
      "metadata": {
        "id": "-LdyuHrrPigD"
      },
      "source": [
        "###**Installing Packages (local)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B5KuCCFhOgpA",
      "metadata": {
        "id": "B5KuCCFhOgpA"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !sudo apt-get install lz4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B0TrOX90OhV_",
      "metadata": {
        "id": "B0TrOX90OhV_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pydicom google-cloud-bigquery pyarrow db_dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73LFRISZPn6Q",
      "metadata": {
        "id": "73LFRISZPn6Q"
      },
      "source": [
        "###**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4585bb-9bfb-4de3-882a-c7454c7ec3af",
      "metadata": {
        "id": "db4585bb-9bfb-4de3-882a-c7454c7ec3af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import traceback\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import subprocess  # Import the subprocess module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Clrt8j70Pb5a",
      "metadata": {
        "id": "Clrt8j70Pb5a"
      },
      "source": [
        "###**Parameters for papermill**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G0ttC6_KPhQ6",
      "metadata": {
        "id": "G0ttC6_KPhQ6",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "segFilesCsv=''\n",
        "jsonServiceAccountFile=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KaMp4d_POUR7",
      "metadata": {
        "id": "KaMp4d_POUR7"
      },
      "outputs": [],
      "source": [
        "!gcloud auth activate-service-account --key-file={jsonServiceAccountFile}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kgt7OeFzP1BX",
      "metadata": {
        "id": "Kgt7OeFzP1BX"
      },
      "outputs": [],
      "source": [
        "data= pd.read_csv(segFilesCsv)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qVSsZg0q2P4P",
      "metadata": {
        "id": "qVSsZg0q2P4P"
      },
      "outputs": [],
      "source": [
        "# # Add a new column called 'new_destination' to your DataFrame\n",
        "# data['new_destination'] = ''\n",
        "\n",
        "# # Populate the 'new_destination' column with values that are a concatenation of 'bucket_id' and 'batch_id'\n",
        "# data['new_destination'] = data[\"dicomsegAndRadiomicsSR_CompressedFiles\"] +' '+'gs://perframefunctionalgroupssequence/' +'batch_'+ data['entity:twoVM_2023_07_07_22_16_id'].astype(str)+'/'\n",
        "\n",
        "# data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A8fR5Xcl3c-G",
      "metadata": {
        "id": "A8fR5Xcl3c-G"
      },
      "outputs": [],
      "source": [
        "# !gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xlvUT07E3jzA",
      "metadata": {
        "id": "xlvUT07E3jzA"
      },
      "outputs": [],
      "source": [
        "# !gcloud config set project 'idc-external-025'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SRS2TbP32oUJ",
      "metadata": {
        "id": "SRS2TbP32oUJ"
      },
      "outputs": [],
      "source": [
        "# urls= data['new_destination'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Aldc3kZN3xoR",
      "metadata": {
        "id": "Aldc3kZN3xoR"
      },
      "outputs": [],
      "source": [
        "# for url in urls:\n",
        "#   !gsutil cp {url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f4509f-6ea7-453a-8f55-e056c3eb817e",
      "metadata": {
        "id": "44f4509f-6ea7-453a-8f55-e056c3eb817e"
      },
      "outputs": [],
      "source": [
        "# Initialize logging\n",
        "logging.basicConfig(filename=\"console_output.txt\", level=logging.INFO)\n",
        "\n",
        "# Create an output directory to store CSV or Parquet files\n",
        "output_dir = 'output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "seg_download_urls = data['new_destination'].to_list()\n",
        "batch_count = 1  # Counter for batch folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d26eb35c-9094-48d5-819d-a6cc724057cb",
      "metadata": {
        "id": "d26eb35c-9094-48d5-819d-a6cc724057cb"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     for url in tqdm(seg_download_urls):\n",
        "#         logging.info('Processing URL: %s', url)\n",
        "\n",
        "#         # Clean up previous data if necessary\n",
        "#         try:\n",
        "#             shutil.rmtree('itkimage2segimage')\n",
        "#             shutil.rmtree('decompressedSegmentationsDICOM')\n",
        "#         except OSError:\n",
        "#             pass\n",
        "\n",
        "#         os.mkdir('decompressedSegmentationsDICOM')\n",
        "#         # Download and process the data\n",
        "#         try:\n",
        "#             # Download and decompress data\n",
        "#             !gsutil cp {url} . > /dev/null 2>&1\n",
        "#             !lz4 -d --rm dicomsegAndRadiomicsSR_DICOMsegFiles.tar.lz4 -c | tar --strip-components=1 -xvf - > /dev/null 2>&1\n",
        "#             !find ./itkimage2segimage -name '*.dcm.lz4' -exec mv -t decompressedSegmentationsDICOM {} + > /dev/null 2>&1\n",
        "#             !lz4 -d -m --rm \"decompressedSegmentationsDICOM\"/*.lz4 > /dev/null 2>&1\n",
        "#             print('files successfully decompressed')\n",
        "#         except Exception as download_error:\n",
        "#             logging.error('Error during download and decompression: %s', str(download_error))\n",
        "#             continue  # Skip this batch and continue to the next\n",
        "\n",
        "#         # # Create a batch folder\n",
        "#         # batch_folder = os.path.join(output_dir, f'batch_{batch_count}')\n",
        "#         # os.makedirs(batch_folder, exist_ok=True)\n",
        "\n",
        "#         # Find all series IDs and add them to the DataFrame\n",
        "#         series_ids = [filename.split('_')[0] for filename in os.listdir('decompressedSegmentationsDICOM')]\n",
        "#         # Create a list to hold data from all series in the batch\n",
        "#         batch_data = []\n",
        "\n",
        "#         for series_id in series_ids:\n",
        "#             pffgs = pydicom.dcmread(f'decompressedSegmentationsDICOM/{series_id}', specific_tags=[\"ReferencedSeriesSequence\",\"PerFrameFunctionalGroupsSequence\"], stop_before_pixels=True)\n",
        "#             referencedSeriesInstanceUID = pffgs.ReferencedSeriesSequence[0].SeriesInstanceUID\n",
        "#             data = []\n",
        "#             # Extract data from Per-frame Functional Groups Sequence\n",
        "#             if \"PerFrameFunctionalGroupsSequence\" in pffgs:\n",
        "#                 for item in pffgs.PerFrameFunctionalGroupsSequence:\n",
        "#                     frame_data = {\n",
        "#                         'ReferencedSeriesSequence_SeriesInstanceUID': referencedSeriesInstanceUID,\n",
        "#                         'FrameContentSequence_DimensionIndexValues': [str(s) for s in list(item.FrameContentSequence[0].DimensionIndexValues)],\n",
        "#                         'PlanePositionSequence_ImagePositionPatient': [str(s) for s in list(item.PlanePositionSequence[0].ImagePositionPatient)],\n",
        "#                         'SegmentIdentificationSequence_ReferencedSegmentNumber': item.SegmentIdentificationSequence[0].ReferencedSegmentNumber\n",
        "\n",
        "#                     }\n",
        "\n",
        "#                     # Extract attributes from Derivation Image Sequence\n",
        "#                     derivation_image_sequence = item.DerivationImageSequence\n",
        "#                     if derivation_image_sequence:\n",
        "#                         source_image_sequence = derivation_image_sequence[0].SourceImageSequence\n",
        "#                         if source_image_sequence:\n",
        "#                             frame_data['DerivationImageSequence_SourceImageSequence_ReferencedSOPClassUID'] = source_image_sequence[0].ReferencedSOPClassUID\n",
        "#                             frame_data['DerivationImageSequence_SourceImageSequence_ReferencedSOPInstanceUID'] = source_image_sequence[0].ReferencedSOPInstanceUID\n",
        "#                             purpose_of_reference_code_sequence= source_image_sequence[0].PurposeOfReferenceCodeSequence\n",
        "#                             if purpose_of_reference_code_sequence:\n",
        "#                                 frame_data['DerivationImageSequence_SourceImageSequence_PurposeOfReferenceCodeSequence_CodeValue'] = purpose_of_reference_code_sequence[0].CodeValue\n",
        "#                                 frame_data['DerivationImageSequence_SourceImageSequence_PurposeOfReferenceCodeSequence_CodingSchemeDesignator'] = purpose_of_reference_code_sequence[0].CodingSchemeDesignator\n",
        "#                                 frame_data['DerivationImageSequence_SourceImageSequence_PurposeOfReferenceCodeSequence_CodeMeaning'] = purpose_of_reference_code_sequence[0].CodeMeaning\n",
        "#                     # Extract attributes from Derivation Code Sequence\n",
        "#                     derivation_code_sequence = derivation_image_sequence[0].DerivationCodeSequence\n",
        "#                     if derivation_code_sequence:\n",
        "#                         frame_data['DerivationImageSequence_DerivationCodeSequence_CodeValue'] = derivation_code_sequence[0].CodeValue\n",
        "#                         frame_data['DerivationImageSequence_DerivationCodeSequence_CodingSchemeDesignator'] = derivation_code_sequence[0].CodingSchemeDesignator\n",
        "#                         frame_data['DerivationImageSequence_DerivationCodeSequence_CodeMeaning'] = derivation_code_sequence[0].CodeMeaning\n",
        "\n",
        "#                     data.append(frame_data)\n",
        "\n",
        "#             # Add data from this series to the batch_data list\n",
        "#             batch_data.extend(data)\n",
        "\n",
        "#         # Create a DataFrame from the batch_data list\n",
        "#         df = pd.DataFrame(batch_data)\n",
        "\n",
        "#         # Generate a single CSV file for the batch\n",
        "#         csv_filename = os.path.join(output_dir, f'batch_{batch_count}.csv')\n",
        "#         df.to_csv(csv_filename, index=False)\n",
        "\n",
        "#         # Compress the CSV file using lz4\n",
        "#         #compressed_csv_filename = f'batch_{batch_count}.csv.lz4'\n",
        "#         #subprocess.run([\"lz4\", csv_filename, compressed_csv_filename])\n",
        "\n",
        "#         batch_count += 1\n",
        "#         # perFrame_job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
        "#         # perFrame_job = client.load_table_from_dataframe(df, \"idc-external-025.terra.perFrameTest\",job_config=perFrame_job_config)\n",
        "\n",
        "# except Exception as e:\n",
        "#     logging.error('An error occurred: %s', str(e))\n",
        "\n",
        "# finally:\n",
        "#     logging.info('Processing complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fFg4Vpa_gwuv",
      "metadata": {
        "id": "fFg4Vpa_gwuv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize an empty list to store data from all URLs\n",
        "combined_data = []\n",
        "\n",
        "try:\n",
        "    for url in tqdm(seg_download_urls):\n",
        "        logging.info('Processing URL: %s', url)\n",
        "\n",
        "        # Clean up previous data if necessary\n",
        "        try:\n",
        "            shutil.rmtree('itkimage2segimage')\n",
        "            shutil.rmtree('decompressedSegmentationsDICOM')\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "        os.mkdir('decompressedSegmentationsDICOM')\n",
        "        # Download and process the data\n",
        "        try:\n",
        "            # Download and decompress data\n",
        "            !gsutil cp {url} . > /dev/null 2>&1\n",
        "            !lz4 -d --rm dicomsegAndRadiomicsSR_DICOMsegFiles.tar.lz4 -c | tar --strip-components=1 -xvf - > /dev/null 2>&1\n",
        "            !find ./itkimage2segimage -name '*.dcm.lz4' -exec mv -t decompressedSegmentationsDICOM {} + > /dev/null 2>&1\n",
        "            !lz4 -d -m --rm \"decompressedSegmentationsDICOM\"/*.lz4 > /dev/null 2>&1\n",
        "            print('files successfully decompressed')\n",
        "        except Exception as download_error:\n",
        "            logging.error('Error during download and decompression: %s', str(download_error))\n",
        "            continue  # Skip this URL and continue to the next\n",
        "\n",
        "        # Find all series IDs and add them to the combined_data list\n",
        "        series_ids = [filename.split('_')[0] for filename in os.listdir('decompressedSegmentationsDICOM')]\n",
        "\n",
        "        for series_id in series_ids:\n",
        "            pffgs = pydicom.dcmread(f'decompressedSegmentationsDICOM/{series_id}', specific_tags=[\"ReferencedSeriesSequence\",\"PerFrameFunctionalGroupsSequence\"], stop_before_pixels=True)\n",
        "            referencedSeriesInstanceUID = pffgs.ReferencedSeriesSequence[0].SeriesInstanceUID\n",
        "            data = []\n",
        "\n",
        "            # Extract data from Per-frame Functional Groups Sequence\n",
        "            if \"PerFrameFunctionalGroupsSequence\" in pffgs:\n",
        "                for item in pffgs.PerFrameFunctionalGroupsSequence:\n",
        "                    frame_data = {\n",
        "                        'ReferencedSeriesSequence_SeriesInstanceUID': referencedSeriesInstanceUID,\n",
        "                        'FrameContentSequence_DimensionIndexValues': [str(s) for s in list(item.FrameContentSequence[0].DimensionIndexValues)],\n",
        "                        'PlanePositionSequence_ImagePositionPatient': [str(s) for s in list(item.PlanePositionSequence[0].ImagePositionPatient)],\n",
        "                        'SegmentIdentificationSequence_ReferencedSegmentNumber': item.SegmentIdentificationSequence[0].ReferencedSegmentNumber\n",
        "                    }\n",
        "\n",
        "                    # Extract attributes from Derivation Image Sequence\n",
        "                    derivation_image_sequence = item.DerivationImageSequence\n",
        "                    if derivation_image_sequence:\n",
        "                        source_image_sequence = derivation_image_sequence[0].SourceImageSequence\n",
        "                        if source_image_sequence:\n",
        "                            frame_data['DerivationImageSequence_SourceImageSequence_ReferencedSOPClassUID'] = source_image_sequence[0].ReferencedSOPClassUID\n",
        "                            frame_data['DerivationImageSequence_SourceImageSequence_ReferencedSOPInstanceUID'] = source_image_sequence[0].ReferencedSOPInstanceUID\n",
        "                            purpose_of_reference_code_sequence = source_image_sequence[0].PurposeOfReferenceCodeSequence\n",
        "                            if purpose_of_reference_code_sequence:\n",
        "                                frame_data['DerivationImageSequence_SourceImageSequence_PurposeOfReferenceCodeSequence_CodeValue'] = purpose_of_reference_code_sequence[0].CodeValue\n",
        "                                frame_data['DerivationImageSequence_SourceImageSequence_PurposeOfReferenceCodeSequence_CodingSchemeDesignator'] = purpose_of_reference_code_sequence[0].CodingSchemeDesignator\n",
        "                                frame_data['DerivationImageSequence_SourceImageSequence_PurposeOfReferenceCodeSequence_CodeMeaning'] = purpose_of_reference_code_sequence[0].CodeMeaning\n",
        "\n",
        "                    # Extract attributes from Derivation Code Sequence\n",
        "                    derivation_code_sequence = derivation_image_sequence[0].DerivationCodeSequence\n",
        "                    if derivation_code_sequence:\n",
        "                        frame_data['DerivationImageSequence_DerivationCodeSequence_CodeValue'] = derivation_code_sequence[0].CodeValue\n",
        "                        frame_data['DerivationImageSequence_DerivationCodeSequence_CodingSchemeDesignator'] = derivation_code_sequence[0].CodingSchemeDesignator\n",
        "                        frame_data['DerivationImageSequence_DerivationCodeSequence_CodeMeaning'] = derivation_code_sequence[0].CodeMeaning\n",
        "\n",
        "                    data.append(frame_data)\n",
        "\n",
        "            # Add data from this series to the combined_data list\n",
        "            combined_data.extend(data)\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error('An error occurred: %s', str(e))\n",
        "\n",
        "finally:\n",
        "    # Create a DataFrame from the combined_data list\n",
        "    df = pd.DataFrame(combined_data)\n",
        "\n",
        "    # Generate a single CSV file for all the data\n",
        "    csv_filename = 'perFrameFunctionalGroupSequence.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "    !lz4 --rm 'perFrameFunctionalGroupSequence.csv' 'perFrameFunctionalGroupSequence.csv.lz4'\n",
        "\n",
        "    logging.info('Processing complete.')\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}