{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkt1414/Cloud-Resources-Workflows/blob/main/Notebooks/Totalsegmentator/structuredReports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZnoRi9Y7nEB"
      },
      "source": [
        "# **Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FLzDDB9dEae"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "\n",
        "!pip install pyradiomics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages for both use cases. "
      ],
      "metadata": {
        "id": "pHlRsAvxE_4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "non5qVLIcG4M",
        "outputId": "93693d1d-e82c-43b6-e0de-ecf6795de925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May  5 19:10:13 2023\n",
            "\n",
            "Current directory : /content\n",
            "Hostname          : 2cdbd990a57a\n",
            "Username          : root\n",
            "Python version    : 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import yaml\n",
        "import time\n",
        "import tqdm\n",
        "import copy\n",
        "import json \n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# useful information\n",
        "curr_dir = !pwd\n",
        "curr_droid = !hostname\n",
        "curr_pilot = !whoami\n",
        "\n",
        "print(time.asctime(time.localtime()))\n",
        "\n",
        "print(\"\\nCurrent directory :\", curr_dir[-1])\n",
        "print(\"Hostname          :\", curr_droid[-1])\n",
        "print(\"Username          :\", curr_pilot[-1])\n",
        "\n",
        "print(\"Python version    :\", sys.version.split('\\n')[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the other packages that nnUNet and BPR depend on. "
      ],
      "metadata": {
        "id": "GpZSBCG4FEgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install and import the packages needed to create Structured Reports (SR). "
      ],
      "metadata": {
        "id": "23B3Xy8buP45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages for the structured report \n",
        "\n",
        "!pip uninstall highdicom\n",
        "!git clone https://github.com/herrmannlab/highdicom.git\n",
        "#!cd highdicom && python setup.py install\n",
        "!cd highdicom && pip install .\n",
        "\n",
        "import highdicom\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import highdicom as hd\n",
        "\n",
        "from pydicom.uid import generate_uid\n",
        "from pydicom.filereader import dcmread\n",
        "from pydicom.sr.codedict import codes\n",
        "\n",
        "from highdicom.sr.content import (\n",
        "    FindingSite,\n",
        "    ImageRegion,\n",
        "    ImageRegion3D,\n",
        "    SourceImageForRegion,\n",
        "    SourceImageForMeasurement,\n",
        "    SourceImageForMeasurementGroup\n",
        ")\n",
        "from highdicom.sr.enum import GraphicTypeValues3D\n",
        "from highdicom.sr.enum import GraphicTypeValues\n",
        "from highdicom.sr.sop import Comprehensive3DSR, ComprehensiveSR\n",
        "from highdicom.sr.templates import (\n",
        "    DeviceObserverIdentifyingAttributes,\n",
        "    Measurement,\n",
        "    MeasurementProperties,\n",
        "    MeasurementReport,\n",
        "    MeasurementsAndQualitativeEvaluations,\n",
        "    ObservationContext,\n",
        "    ObserverContext,\n",
        "    PersonObserverIdentifyingAttributes,\n",
        "    PlanarROIMeasurementsAndQualitativeEvaluations,\n",
        "    RelationshipTypeValues,\n",
        "    TrackingIdentifier,\n",
        "    QualitativeEvaluation,\n",
        "    ImageLibrary,\n",
        "    ImageLibraryEntryDescriptors\n",
        ")\n",
        "from highdicom.sr.value_types import (\n",
        "    CodedConcept,\n",
        "    CodeContentItem,\n",
        ")\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger(\"highdicom.sr.sop\")\n",
        "logger.setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "m0Ijwc0uuT4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1GXUtRRrIlT"
      },
      "source": [
        "Copy the JSON metadata file (generated using [...]) from the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VQiQ9Zw9rMoD",
        "outputId": "dd2ed1be-863d-4bee-cb48-e9fafdf39872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             shape_feature quantity_CodingSchemeDesignator quantity_CodeValue  \\\n",
              "0               Elongation                            IBSI               Q3CK   \n",
              "1                 Flatness                            IBSI               N17B   \n",
              "2          LeastAxisLength                            IBSI               7J51   \n",
              "3          MajorAxisLength                            IBSI               TDIC   \n",
              "4        Maximum3DDiameter                            IBSI               L0JK   \n",
              "5               MeshVolume                            IBSI               RNU0   \n",
              "6          MinorAxisLength                            IBSI               P9VJ   \n",
              "7               Sphericity                            IBSI               QCFX   \n",
              "8              SurfaceArea                            IBSI               C0JK   \n",
              "9       SurfaceVolumeRatio                            IBSI               2PR5   \n",
              "10             VoxelVolume                            IBSI               YEKZ   \n",
              "11            Compactness1                            IBSI               SKGS   \n",
              "12            Compactness2                            IBSI               BQWJ   \n",
              "13  SphericalDisproportion                            IBSI               KRCK   \n",
              "\n",
              "             quantity_CodeMeaning units_CodingSchemeDesignator  \\\n",
              "0                      Elongation                         UCUM   \n",
              "1                        Flatness                         UCUM   \n",
              "2         Least Axis in 3D Length                         UCUM   \n",
              "3         Major Axis in 3D Length                         UCUM   \n",
              "4   Maximum 3D Diameter of a Mesh                         UCUM   \n",
              "5                  Volume of Mesh                         UCUM   \n",
              "6         Minor Axis in 3D Length                         UCUM   \n",
              "7                      Sphericity                         UCUM   \n",
              "8            Surface Area of Mesh                         UCUM   \n",
              "9         Surface to Volume Ratio                         UCUM   \n",
              "10    Volume from Voxel Summation                         UCUM   \n",
              "11                  Compactness 1                         UCUM   \n",
              "12                  Compactness 2                         UCUM   \n",
              "13        Spherical Disproportion                         UCUM   \n",
              "\n",
              "   units_CodeValue  units_CodeMeaning  \n",
              "0               mm         millimeter  \n",
              "1               mm         millimeter  \n",
              "2               mm         millimeter  \n",
              "3               mm         millimeter  \n",
              "4               mm         millimeter  \n",
              "5              mm3  cubic millimeter   \n",
              "6               mm         millimeter  \n",
              "7                1           no units  \n",
              "8              mm2  square millimeter  \n",
              "9              /mm     per millimeter  \n",
              "10             mm3   cubic millimeter  \n",
              "11               1           no units  \n",
              "12               1           no units  \n",
              "13               1           no units  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9addaee-f282-4d01-86cb-fa62cd24ef2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shape_feature</th>\n",
              "      <th>quantity_CodingSchemeDesignator</th>\n",
              "      <th>quantity_CodeValue</th>\n",
              "      <th>quantity_CodeMeaning</th>\n",
              "      <th>units_CodingSchemeDesignator</th>\n",
              "      <th>units_CodeValue</th>\n",
              "      <th>units_CodeMeaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elongation</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>Q3CK</td>\n",
              "      <td>Elongation</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm</td>\n",
              "      <td>millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Flatness</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>N17B</td>\n",
              "      <td>Flatness</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm</td>\n",
              "      <td>millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LeastAxisLength</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>7J51</td>\n",
              "      <td>Least Axis in 3D Length</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm</td>\n",
              "      <td>millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MajorAxisLength</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>TDIC</td>\n",
              "      <td>Major Axis in 3D Length</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm</td>\n",
              "      <td>millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Maximum3DDiameter</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>L0JK</td>\n",
              "      <td>Maximum 3D Diameter of a Mesh</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm</td>\n",
              "      <td>millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MeshVolume</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>RNU0</td>\n",
              "      <td>Volume of Mesh</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm3</td>\n",
              "      <td>cubic millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MinorAxisLength</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>P9VJ</td>\n",
              "      <td>Minor Axis in 3D Length</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm</td>\n",
              "      <td>millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sphericity</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>QCFX</td>\n",
              "      <td>Sphericity</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>1</td>\n",
              "      <td>no units</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SurfaceArea</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>C0JK</td>\n",
              "      <td>Surface Area of Mesh</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm2</td>\n",
              "      <td>square millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SurfaceVolumeRatio</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>2PR5</td>\n",
              "      <td>Surface to Volume Ratio</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>/mm</td>\n",
              "      <td>per millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>VoxelVolume</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>YEKZ</td>\n",
              "      <td>Volume from Voxel Summation</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>mm3</td>\n",
              "      <td>cubic millimeter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Compactness1</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>SKGS</td>\n",
              "      <td>Compactness 1</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>1</td>\n",
              "      <td>no units</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Compactness2</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>BQWJ</td>\n",
              "      <td>Compactness 2</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>1</td>\n",
              "      <td>no units</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SphericalDisproportion</td>\n",
              "      <td>IBSI</td>\n",
              "      <td>KRCK</td>\n",
              "      <td>Spherical Disproportion</td>\n",
              "      <td>UCUM</td>\n",
              "      <td>1</td>\n",
              "      <td>no units</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9addaee-f282-4d01-86cb-fa62cd24ef2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9addaee-f282-4d01-86cb-fa62cd24ef2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9addaee-f282-4d01-86cb-fa62cd24ef2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# bucket_data_base_uri = os.path.join(bucket_base_uri, \"nnunet/data\")\n",
        "# dicomseg_json_uri = \"s3://idc-medima-paper/nnunet/data/dicomseg_metadata.json\"\n",
        "# dicomseg_json_path = \"/content/data/dicomseg_metadata.json\"\n",
        "\n",
        "# !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $dicomseg_json_uri $dicomseg_json_path\n",
        "\n",
        "dicomseg_json_path = \"/content/data/dicomseg_metadata.json\"\n",
        "!wget -q -N -P '/content/data' https://raw.githubusercontent.com/ImagingDataCommons/ai_medima_misc/main/nnunet/data/dicomseg_metadata.json\n",
        "!wget -q -N https://raw.githubusercontent.com/ImagingDataCommons/ai_medima_misc/main/nnunet/data/nnunet_segments_code_mapping.csv\n",
        "nnunet_segments_code_mapping_df = pd.read_csv(\"nnunet_segments_code_mapping.csv\")\n",
        "\n",
        "!wget -q -N https://raw.githubusercontent.com/ImagingDataCommons/ai_medima_misc/main/nnunet/data/nnunet_shape_features_code_mapping.csv\n",
        "nnunet_shape_features_code_mapping_df = pd.read_csv(\"nnunet_shape_features_code_mapping.csv\")\n",
        "nnunet_shape_features_code_mapping_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract list of first order features mentioned in TotalSegmentator"
      ],
      "metadata": {
        "id": "y_i2E7yjfUGQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Z2S0OdAtkz"
      },
      "source": [
        "---\n",
        "\n",
        "# **Function Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF9cFrUlx-dk"
      },
      "outputs": [],
      "source": [
        "def modify_dicomseg_json_file(dicomseg_json_path, dicomseg_json_path_modified, SegmentAlgorithmName):\n",
        "\n",
        "  \"\"\"\n",
        "  This function writes out a new metadata json file for the DICOM Segmentation object. \n",
        "  It sets the SegmentAlgorithmName to the one provided as input. \n",
        "\n",
        "  Arguments:\n",
        "    dicomseg_json_path          : path of the original dicomseg json file \n",
        "    dicomseg_json_path_modified : the new json file to write to disk \n",
        "    SegmentAlgorithmName        : the field to replace\n",
        "    \n",
        "  Returns:\n",
        "    The json file is written out to dicomseg_json_path_modified \n",
        "\n",
        "  \"\"\"\n",
        "  f = open(dicomseg_json_path)\n",
        "  meta_json = json.load(f)\n",
        "\n",
        "  meta_json_modified = copy.deepcopy(meta_json)\n",
        "  num_regions = len(meta_json_modified['segmentAttributes'])\n",
        "  for n in range(0,num_regions): \n",
        "    meta_json_modified['segmentAttributes'][n][0]['SegmentAlgorithmName'] = SegmentAlgorithmName\n",
        "\n",
        "  with open(dicomseg_json_path_modified, 'w') as f: \n",
        "    json.dump(meta_json_modified, f)\n",
        "\n",
        "  return \n",
        "\n",
        "  # dicomseg_json_uri = \"s3://idc-medima-paper/nnunet/data/dicomseg_metadata.json\"\n",
        "  # dicomseg_json_path = \"/content/data/dicomseg_metadata.json\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nnUNet 3D shape features SR creation"
      ],
      "metadata": {
        "id": "dO1EPJ6rdcV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_and_names_from_metadata_json(dicomseg_json):\n",
        "\n",
        "  \"\"\"Returns two lists containing the label values and the corresponding\n",
        "     CodeMeaning values\n",
        "\n",
        "  Inputs: \n",
        "    dicomseg_json : metajson file\n",
        "\n",
        "  Outputs:\n",
        "    label_values  : label values from the metajson file \n",
        "    label_names   : the corresponding CodeMeaning values \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  f = open(dicomseg_json)\n",
        "  meta_json = json.load(f)\n",
        "\n",
        "  print(meta_json)\n",
        "\n",
        "  num_regions = len(meta_json['segmentAttributes'][0])\n",
        "  print ('num_regions: ' + str(num_regions))\n",
        "\n",
        "  label_values = []\n",
        "  label_names = [] \n",
        "  for n in range(0,num_regions):\n",
        "    # label_values.append(n)\n",
        "    label_value = meta_json['segmentAttributes'][0][n]['labelID']\n",
        "    label_name = meta_json['segmentAttributes'][0][n]['SegmentedPropertyTypeCodeSequence']['CodeMeaning']\n",
        "    label_values.append(label_value)\n",
        "    label_names.append(label_name)\n",
        "\n",
        "  return label_values, label_names "
      ],
      "metadata": {
        "id": "UpPtxw3hbfwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pyradiomics_3D_features(ct_nifti_path, \n",
        "                                    label_values, \n",
        "                                    label_names, \n",
        "                                    split_pred_nifti_path, \n",
        "                                    nnunet_shape_features_code_mapping_df):\n",
        "\n",
        "  \"\"\"Function to compute pyradiomics 3D features for each label in a nifti file. \n",
        "     A single csv file is written out to disk. \n",
        "\n",
        "  Inputs: \n",
        "    ct_nifti_path            : the CT nifti file \n",
        "    label_values             : the label value for each of the segments from the json file \n",
        "    label_names              : the corresponding label name for each of the segments \n",
        "    split_pred_nifti_path    : where to save the individual nii segments needed \n",
        "                               for pyradiomics\n",
        "    nnunet_shape_features_code_mapping_df : the df where we will obtain the \n",
        "                                            list of the shape features to \n",
        "                                            compute\n",
        "\n",
        "  Outputs:\n",
        "    Writes the features_csv_path_nnunet to disk. \n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  # Get the names of the features from the nnunet_shape_features_code_mapping_df\n",
        "  shape_features = list(nnunet_shape_features_code_mapping_df['shape_feature'].values)\n",
        "\n",
        "  # Instantiate the extractor and modify the settings to keep the 3D shape features\n",
        "  extractor = featureextractor.RadiomicsFeatureExtractor()\n",
        "  extractor.settings['minimumROIDimensions'] = 3 \n",
        "  extractor.disableAllFeatures()\n",
        "  extractor.enableFeaturesByName(shape=shape_features) \n",
        "\n",
        "  # Calculate features for each label and create a dataframe\n",
        "  num_labels = len([f for f in os.listdir(split_pred_nifti_path) if f.endswith('.nii.gz')])\n",
        "  df_list = [] \n",
        "  for n in range(0,num_labels):\n",
        "    mask_path = os.path.join(split_pred_nifti_path, label_names[n] + '.nii.gz')\n",
        "    # Run the extractor \n",
        "    result = extractor.execute(ct_nifti_path, mask_path) # dictionary\n",
        "    # keep only the features we want\n",
        "    # Get the corresponding label number -- all might not be present \n",
        "    corresponding_label_value = label_values[label_names.index(label_names[n])] \n",
        "    dict_keep = {'ReferencedSegment': corresponding_label_value, \n",
        "                 'label_name': label_names[n]}\n",
        "    keys_keep = [f for f in result.keys() if 'original_shape' in f]\n",
        "    # Just keep the feature keys we want\n",
        "    dict_keep_new_values = {key_keep: result[key_keep] for key_keep in keys_keep}\n",
        "    dict_keep.update(dict_keep_new_values)\n",
        "    df1 = pd.DataFrame([dict_keep])\n",
        "    # change values of columns to remove original_shape_\n",
        "    df1.columns = df1.columns.str.replace('original_shape_', '')\n",
        "    # Append to the ReferencedSegment and label_name df \n",
        "    df_list.append(df1)\n",
        "\n",
        "  # concat all label features \n",
        "  df = pd.concat(df_list)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "UYDxAx7sbbPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def order_dicom_files_image_position(dcm_directory):\n",
        "  \"\"\"\n",
        "  Orders the dicom files according to image position and orientation. \n",
        "\n",
        "  Arguments:\n",
        "    dcm_directory : input directory of dcm files to put in order \n",
        "\n",
        "  Outputs:\n",
        "    files_sorted   : dcm files in sorted order \n",
        "    sop_all_sorted : the SOPInstanceUIDs in sorted order \n",
        "    pos_all_sorted : the image position in sorted order \n",
        "\n",
        "  \"\"\"\n",
        "  files = [os.path.join(dcm_directory,f) for f in os.listdir(dcm_directory)]\n",
        "\n",
        "  num_files = len(files)\n",
        "\n",
        "  pos_all = []  \n",
        "  sop_all = [] \n",
        "\n",
        "  for n in range(0,num_files):\n",
        "    # read dcm file \n",
        "    filename = files[n]\n",
        "    ds = dcmread(filename)\n",
        "\n",
        "    # get ImageOrientation (0020, 0037)\n",
        "    # ImageOrientation = ds['0x0020','0x0037'].value\n",
        "    ImageOrientation = ds.ImageOrientationPatient\n",
        "\n",
        "    # get ImagePositionPatient (0020, 0032) \n",
        "    # ImagePositionPatient = ds['0x0020','0x0032'].value\n",
        "    ImagePositionPatient = ds.ImagePositionPatient\n",
        "\n",
        "    # calculate z value\n",
        "    x_vector = ImageOrientation[0:3]\n",
        "    y_vector = ImageOrientation[3:]\n",
        "    z_vector = np.cross(x_vector,y_vector)\n",
        "\n",
        "    # multiple z_vector by ImagePositionPatient\n",
        "    pos = np.dot(z_vector,ImagePositionPatient)\n",
        "    pos_all.append(pos)\n",
        "\n",
        "    # get the SOPInstanceUID \n",
        "    # sop = ds['0x0008', '0x0018'].value\n",
        "    sop = ds.SOPInstanceUID\n",
        "    sop_all.append(sop)\n",
        "\n",
        "\n",
        "  #----- order the SOPInstanceUID/files by z value ----# \n",
        "\n",
        "  sorted_ind = np.argsort(pos_all)\n",
        "  pos_all_sorted = np.array(pos_all)[sorted_ind.astype(int)]\n",
        "  sop_all_sorted = np.array(sop_all)[sorted_ind.astype(int)]\n",
        "  files_sorted = np.array(files)[sorted_ind.astype(int)]\n",
        "\n",
        "  return files_sorted, sop_all_sorted, pos_all_sorted "
      ],
      "metadata": {
        "id": "citIHr-gboSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_structured_report_metajson_for_shape_features(SeriesInstanceUID, \n",
        "                                                         SOPInstanceUID_seg,\n",
        "                                                         seg_file, \n",
        "                                                         dcm_directory, \n",
        "                                                         segments_code_mapping_df,\n",
        "                                                         shape_features_code_mapping_df,\n",
        "                                                         df_features, \n",
        "                                                         ):\n",
        "  \n",
        "  \"\"\"Function that creates the metajson necessary for the creation of a\n",
        "  structured report from a pandas dataframe of label names and features for \n",
        "  each. \n",
        "\n",
        "  Inputs: \n",
        "    SeriesInstanceUID               : SeriesInstanceUID of the corresponding CT \n",
        "                                      file \n",
        "    SOPInstanceUID_seg              : SOPInstanceUID of the corresponding SEG file \n",
        "    seg_file                        : filename of SEG DCM file \n",
        "    dcm_directory                   : ct directory that will be sorted in \n",
        "                                      terms of axial ordering according to the \n",
        "                                      ImagePositionPatient and ImageOrientation \n",
        "                                      fields\n",
        "    segments_code_mapping_df        : dataframe that holds the names of the \n",
        "                                      segments and the associated code values etc.\n",
        "    shape_features_code_mapping_df  : dataframe that holds the names of the \n",
        "                                      features and the associated code values etc. \n",
        "    df_features                     : a pandas dataframe holding the segments and a \n",
        "                                      set of 3D shape features for each \n",
        "\n",
        "  Outputs:\n",
        "    Returns the metajson for the structured report that will then be used by\n",
        "    dcmqi tid1500writer to create a structured report \n",
        "  \"\"\" \n",
        "\n",
        "  # --- Get the version number for the pyradiomics package --- #\n",
        "\n",
        "  pyradiomics_version_number = str(radiomics.__version__)\n",
        "  \n",
        "  # --- Sort the dcm files first according to --- # \n",
        "  # --- ImagePositionPatient and ImageOrientation --- #\n",
        "\n",
        "  files_sorted, sop_all_sorted, pos_all_sorted = order_dicom_files_image_position(dcm_directory)\n",
        "  files_sorted = [os.path.basename(f) for f in files_sorted]\n",
        "\n",
        "  # --- Create the header for the json --- # \n",
        "  \n",
        "  inputMetadata = {}\n",
        "  inputMetadata[\"@schema\"]= \"https://raw.githubusercontent.com/qiicr/dcmqi/master/doc/schemas/sr-tid1500-schema.json#\"\n",
        "  inputMetadata[\"SeriesDescription\"] = \"Measurements\"\n",
        "  inputMetadata[\"SeriesNumber\"] = \"1001\"\n",
        "  inputMetadata[\"InstanceNumber\"] = \"1\"\n",
        "\n",
        "  inputMetadata[\"compositeContext\"] = [seg_file] # not full path\n",
        "\n",
        "  inputMetadata[\"imageLibrary\"] = files_sorted # not full path \n",
        "\n",
        "  # inputMetadata[\"observerContext\"] = {\n",
        "  #                                     \"ObserverType\": \"PERSON\",\n",
        "  #                                     \"PersonObserverName\": \"Reader1\"\n",
        "  #                                   }\n",
        "  # inputMetadata[\"observerContext\"] = {\n",
        "  #                     \"ObserverType\": \"DEVICE\",\n",
        "  #                     \"DeviceObserverName\": \"pyradiomics\",\n",
        "  #                     \"DeviceObserverModelName\": \"v3.0.1\"\n",
        "  #                   }\n",
        "  inputMetadata[\"observerContext\"] = {\n",
        "                      \"ObserverType\": \"DEVICE\",\n",
        "                      \"DeviceObserverName\": \"pyradiomics\",\n",
        "                      \"DeviceObserverModelName\": pyradiomics_version_number\n",
        "                    }\n",
        "\n",
        "  inputMetadata[\"VerificationFlag\"]  = \"UNVERIFIED\"\n",
        "  inputMetadata[\"CompletionFlag\"] =  \"COMPLETE\"\n",
        "  inputMetadata[\"activitySession\"] = \"1\"\n",
        "  inputMetadata[\"timePoint\"] = \"1\"\n",
        "\n",
        "  # ------------------------------------------------------------------------- # \n",
        "  # --- Create the measurement_dict for each segment - holds all features --- # \n",
        "\n",
        "  measurement = [] \n",
        "\n",
        "  # --- Now create the dict for all features and all segments --- #\n",
        "\n",
        "  # --- Loop over the number of segments --- #\n",
        "\n",
        "  # number of rows in the df_features \n",
        "  num_segments = df_features.shape[0]\n",
        "\n",
        "  # Array of dictionaries - one dictionary for each segment \n",
        "  measurement_across_segments_combined = [] \n",
        "\n",
        "  for segment_id in range(0,num_segments):\n",
        "\n",
        "    ReferencedSegment = df_features['ReferencedSegment'].values[segment_id]\n",
        "    FindingSite = df_features['label_name'].values[segment_id]\n",
        "\n",
        "    print('segment_id: ' + str(segment_id))\n",
        "    print('ReferencedSegment: ' + str(ReferencedSegment))\n",
        "    print('FindingSite: ' + str(FindingSite))\n",
        "\n",
        "    # --- Create the dict for the Measurements group --- # \n",
        "    TrackingIdentifier = \"Measurements group \" + str(ReferencedSegment)\n",
        "\n",
        "    segment_row = segments_code_mapping_df[segments_code_mapping_df[\"segment\"] == FindingSite]\n",
        "    # print(segment_row)\n",
        "        \n",
        "    my_dict = {\n",
        "      \"TrackingIdentifier\": str(TrackingIdentifier),\n",
        "      \"ReferencedSegment\": int(ReferencedSegment),\n",
        "      \"SourceSeriesForImageSegmentation\": str(SeriesInstanceUID),\n",
        "      \"segmentationSOPInstanceUID\": str(SOPInstanceUID_seg),\n",
        "      \"Finding\": {\n",
        "        \"CodeValue\": \"113343008\",\n",
        "        \"CodingSchemeDesignator\": \"SCT\",\n",
        "        \"CodeMeaning\": \"Organ\"\n",
        "      }, \n",
        "      \"FindingSite\": {\n",
        "        \"CodeValue\": str(segment_row[\"FindingSite_CodeValue\"].values[0]),\n",
        "        \"CodingSchemeDesignator\": str(segment_row[\"FindingSite_CodingSchemeDesignator\"].values[0]),\n",
        "        \"CodeMeaning\": str(segment_row[\"FindingSite_CodeMeaning\"].values[0])\n",
        "      }\n",
        "    }\n",
        "\n",
        "    measurement = []  \n",
        "    # number of features - number of columns in df_features - 2 (label_name and ReferencedSegment)\n",
        "    num_values = len(df_features.columns)-2 \n",
        "\n",
        "    feature_list = df_features.columns[2:] # remove first two \n",
        "\n",
        "\n",
        "    # For each measurement per region segment\n",
        "    for n in range(0,num_values): \n",
        "      measurement_dict = {}\n",
        "      row = df_features.loc[df_features['label_name'] == FindingSite]\n",
        "      feature_row = shape_features_code_mapping_df.loc[shape_features_code_mapping_df[\"shape_feature\"] == feature_list[n]]\n",
        "      value = str(np.round(row[feature_list[n]].values[0],3))\n",
        "      measurement_dict[\"value\"] = value\n",
        "      measurement_dict[\"quantity\"] = {}\n",
        "      measurement_dict[\"quantity\"][\"CodeValue\"] = str(feature_row[\"quantity_CodeValue\"].values[0])\n",
        "      measurement_dict[\"quantity\"][\"CodingSchemeDesignator\"] = str(feature_row[\"quantity_CodingSchemeDesignator\"].values[0])\n",
        "      measurement_dict[\"quantity\"][\"CodeMeaning\"] = str(feature_row[\"quantity_CodeMeaning\"].values[0])\n",
        "      measurement_dict[\"units\"] = {}\n",
        "      measurement_dict[\"units\"][\"CodeValue\"] = str(feature_row[\"units_CodeValue\"].values[0])\n",
        "      measurement_dict[\"units\"][\"CodingSchemeDesignator\"] = str(feature_row[\"units_CodingSchemeDesignator\"].values[0])\n",
        "      measurement_dict[\"units\"][\"CodeMeaning\"] = str(feature_row[\"units_CodeMeaning\"].values[0])\n",
        "      measurement_dict[\"measurementAlgorithmIdentification\"] = {}\n",
        "      measurement_dict[\"measurementAlgorithmIdentification\"][\"AlgorithmName\"] = \"pyradiomics\"\n",
        "      measurement_dict[\"measurementAlgorithmIdentification\"][\"AlgorithmVersion\"] = str(pyradiomics_version_number)\n",
        "      measurement.append(measurement_dict) \n",
        "\n",
        "    measurement_combined_dict = {}\n",
        "    measurement_combined_dict['measurementItems'] = measurement # measurement is an array of dictionaries \n",
        "\n",
        "    output_dict_one_segment = {**my_dict, **measurement_combined_dict}\n",
        "\n",
        "    # append to array for all segments \n",
        "\n",
        "    measurement_across_segments_combined.append(output_dict_one_segment)\n",
        "\n",
        "  # --- Add the measurement data --- # \n",
        "\n",
        "  inputMetadata[\"Measurements\"] = {}\n",
        "  inputMetadata[\"Measurements\"] = measurement_across_segments_combined\n",
        "\n",
        "  return inputMetadata"
      ],
      "metadata": {
        "id": "qTuhUJ1Wbt0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_structured_report_for_shape_features(SeriesInstanceUID, \n",
        "                                              SOPInstanceUID_seg, \n",
        "                                              pred_dicomseg_path, \n",
        "                                              dicomseg_json_path, \n",
        "                                              dcm_directory, \n",
        "                                              pred_nifti_path, \n",
        "                                              split_pred_nii_path, \n",
        "                                              ct_nifti_path, \n",
        "                                              segments_code_mapping_df,\n",
        "                                              shape_features_code_mapping_df,\n",
        "                                              sr_json_path,\n",
        "                                              sr_path\n",
        "                                              ):\n",
        "  \n",
        "  \"\"\" This function creates the SR necessary for the nnUNet shape features \n",
        "\n",
        "  Inputs: \n",
        "  SeriesInstanceUID               : SeriesInstanceUID of the corresponding CT \n",
        "                                    file \n",
        "  SOPInstanceUID_seg              : SOPInstanceUID of the corresponding SEG file \n",
        "  pred_dicomseg_path              : filename of DICOM SEG file \n",
        "  dicomseg_json_path              : json file for DICOM SEG file \n",
        "  dcm_directory                   : list of ct files that will be sorted in \n",
        "                                    terms of axial ordering according to the \n",
        "                                    ImagePositionPatient and ImageOrientation \n",
        "                                    fields\n",
        "  pred_nifti_path                 : predictions in nifti format \n",
        "  nnunet_base_path                : path to hold the split nifti files \n",
        "  ct_nifti_path                   : filename for CT nifti file\n",
        "  segments_code_mapping_df        : dataframe that holds the names of the \n",
        "                                    segments and the associated code values etc.\n",
        "  shape_features_code_mapping_df  : dataframe that holds the names of the \n",
        "                                    features and the associated code values etc. \n",
        "  sr_json_path                    : the path that the metajson for the SR for \n",
        "                                    the 3D shape features will be saved \n",
        "  sr_path                         : the path that the SR for the 3D shape \n",
        "                                    features will be saved \n",
        "\n",
        "  Outputs:\n",
        "    Returns the metajson for the structured report that will then be used by\n",
        "    dcmqi tid1500writer to create a structured report \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # --- get label values and names from metajson file --- #\n",
        "  label_values, label_names = get_label_and_names_from_metadata_json(dicomseg_json_path)\n",
        "\n",
        "  # --- split the multilabel nifti into individual files --- #\n",
        "  split_pred_nii_path = os.path.join(nnunet_base_path, \"split_nii\")\n",
        "  if not os.path.isdir(split_pred_nii_path): \n",
        "    os.mkdir(split_pred_nii_path)\n",
        "  split_nii(pred_nifti_path, split_pred_nii_path, label_names)\n",
        "\n",
        "  # --- compute features and save csv for each region --- #\n",
        "  if not os.path.isdir(features_csv_path_nnunet):\n",
        "    os.mkdir(features_csv_path_nnunet) \n",
        "  df_features = compute_pyradiomics_3D_features(ct_nifti_path, \n",
        "                                                label_values, \n",
        "                                                label_names,\n",
        "                                                split_pred_nii_path, \n",
        "                                                nnunet_shape_features_code_mapping_df)\n",
        "  print ('created df_features')\n",
        "  \n",
        "  # --- upload csv file to bucket --- #\n",
        "  # !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $pred_features_csv_path $gs_uri_features_csv_file\n",
        "\n",
        "  # remove nii files after saving out pyradiomics results\n",
        "  !rm $split_pred_nii_path/*\n",
        "  # remove csv \n",
        "  # !rm $pred_features_csv_path\n",
        "\n",
        "  # --- Create the final metadata for the SR --- #\n",
        "  inputMetadata = create_structured_report_metajson_for_shape_features(SeriesInstanceUID, \n",
        "                                                                       SOPInstanceUID_seg,\n",
        "                                                                       pred_dicomseg_path, \n",
        "                                                                       dcm_directory, \n",
        "                                                                       nnunet_segments_code_mapping_df, \n",
        "                                                                       nnunet_shape_features_code_mapping_df,\n",
        "                                                                       df_features)\n",
        "\n",
        "  print ('created SR json for shape features')\n",
        "\n",
        "  # --- Write out json --- #\n",
        "\n",
        "  with open(sr_json_path, 'w') as f:\n",
        "    json.dump(inputMetadata, f, indent=2)\n",
        "  print ('wrote out json for shape features')\n",
        "\n",
        "  # --- Save the SR for nnUNet shape features --- # \n",
        "  # inputImageLibraryDirectory = os.path.join(\"/content\", \"raw\")\n",
        "  # outputDICOM = os.path.join(\"/content\",\"features_sr.dcm\")\n",
        "  # inputCompositeContextDirectory = os.path.join(\"/content\",\"seg\")\n",
        "  inputImageLibraryDirectory = dcm_directory\n",
        "  # outputDICOM = sr_json_path\n",
        "  outputDICOM = sr_path\n",
        "  # the name of the folder where the seg files are located \n",
        "  inputCompositeContextDirectory = os.path.basename(pred_dicomseg_path) # might need to check this\n",
        "  inputMetadata_json = sr_json_path \n",
        "\n",
        "  print ('inputImageLibraryDirectory: ' + str(inputImageLibraryDirectory))\n",
        "  print ('outputDICOM: ' + str(outputDICOM))\n",
        "  print ('inputCompositeContextDirectory: ' + str(inputCompositeContextDirectory))\n",
        "  print ('inputMetadata_json: ' + str(inputMetadata_json)) \n",
        "  !tid1500writer --inputImageLibraryDirectory $inputImageLibraryDirectory \\\n",
        "                --outputDICOM $outputDICOM  \\\n",
        "                --inputCompositeContextDirectory $inputCompositeContextDirectory \\\n",
        "                --inputMetadata $inputMetadata_json\n",
        "  print ('wrote out SR for shape features')\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "Tw5dk1aPec0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq3qnUI2v1Yr"
      },
      "source": [
        "# Putting everything together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Am4M1_dv1Yu"
      },
      "source": [
        "## Running the Per-series Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will run the analysis over each SeriesInstanceUID. "
      ],
      "metadata": {
        "id": "eMs5A5EGdpI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, series_id in enumerate(series_to_process_id_list):\n",
        "\n",
        "\n",
        "  #  -----------------\n",
        "  # init\n",
        "\n",
        "  start_total_nnunet = time.time()\n",
        "\n",
        "  # init every single time, as the most recent logs are loaded from the bucket\n",
        "  inference_time_dict_nnunet = dict()\n",
        "  total_time_dict_nnunet = dict()\n",
        "  inference_time_dict_bpr = dict()\n",
        "  total_time_dict_bpr = dict()\n",
        "\n",
        "  # set up processing flags? - discuss with Dennis \n",
        "\n",
        "  clear_output(wait = True)\n",
        "\n",
        "  print(\"(%g/%g) Processing series %s\"%(idx + 1, len(series_to_process_id_list), series_id))\n",
        "\n",
        "  # Get the dataframe of the series being analyzed \n",
        "  series_df = cohort_df[cohort_df[\"SeriesInstanceUID\"] == series_id]\n",
        "  num_instances = series_df['num_instances'].to_list()[0]\n",
        "\n",
        "  # Get the corresponding PatientId \n",
        "  patient_id = np.unique(series_df[series_df['Modality'] == \"CT\"][\"PatientID\"].values)\n",
        "  assert len(patient_id) == 1 # sanity check - each PatientID should be unique \n",
        "  patient_id = patient_id[0] \n",
        "  print('patient_id: ' + str(patient_id))\n",
        "\n",
        "  # Get the corresponding StudyInstanceUID\n",
        "  study_id = np.unique(series_df[series_df['Modality'] == \"CT\"][\"StudyInstanceUID\"].values)\n",
        "  assert len(study_id) == 1 # sanity check - each StudyInstanceUID should be unique\n",
        "  study_id = study_id[0] \n",
        "  print('study_id: ' + str(study_id))\n",
        "\n",
        "  dicomseg_fn = series_id + \"_SEG.dcm\"\n",
        "\n",
        "  input_nifti_fn = series_id + \"_0000.nii.gz\"\n",
        "  input_nifti_path = os.path.join(model_input_folder_nnunet, input_nifti_fn)\n",
        "\n",
        "  pred_nifti_fn = series_id + \".nii.gz\"\n",
        "  pred_nifti_path = os.path.join(model_output_folder_nnunet, pred_nifti_fn)\n",
        "\n",
        "  pred_softmax_folder_name = \"pred_softmax\"\n",
        "  pred_softmax_folder_path = os.path.join(processed_nrrd_path_nnunet, series_id, pred_softmax_folder_name)\n",
        "\n",
        "  pred_features_csv_fn = series_id + \".csv\"\n",
        "  pred_features_csv_path = os.path.join(features_csv_path_nnunet, pred_features_csv_fn)\n",
        "\n",
        "  sr_fn = series_id + '_SR.dcm'\n",
        "  sr_path = os.path.join(sr_path_nnunet, sr_fn)\n",
        "\n",
        "  sr_json_fn = series_id + '_SR.json'\n",
        "  sr_json_path = os.path.join(sr_path_nnunet, sr_json_fn)\n",
        "\n",
        "  # -----------------\n",
        "  # GS URI definition\n",
        "\n",
        "  # gs URI at which the *nii.gz object is or will be stored in the bucket\n",
        "  gs_uri_nifti_file = os.path.join(bucket_nifti_folder_uri_nnunet, pred_nifti_fn)\n",
        "\n",
        "  # gs URI at which the folder storing the *.nrrd softmax probabilities is or will be stored in the bucket\n",
        "  gs_uri_softmax_pred_folder = os.path.join(bucket_softmax_pred_folder_uri_nnunet, series_id)\n",
        "\n",
        "  # gs URI at which the DICOM SEG object is or will be stored in the bucket\n",
        "  gs_uri_dicomseg_file = os.path.join(bucket_dicomseg_folder_uri_nnunet, dicomseg_fn)\n",
        "\n",
        "  # DK added - gs URI at which the CT to nii file is or will be stored in the bucket \n",
        "  gs_uri_ct_nifti_file = os.path.join(bucket_dicomseg_folder_uri_nnunet, pred_nifti_fn)\n",
        "\n",
        "  # DK added - gs URI at which the features csv is saved if a 3d model is run \n",
        "  # gs_uri_features_csv_file = os.path.join(bucket_features_csv_folder_uri_nnunet, pred_features_csv_fn)\n",
        "  # gs URI at which the DICOM SR ojbect for the shape features is or will be stored in the bucket \n",
        "  gs_uri_sr_file = os.path.join(bucket_sr_folder_uri_nnunet, sr_fn)\n",
        "\n",
        "  # -----------------\n",
        "  # preprocessing\n",
        "\n",
        "  # Download the DICOM data \n",
        "  download_path = os.path.join(sorted_base_path, series_id) # should be deleted after bpr \n",
        "  if not os.path.exists(download_path):\n",
        "    start_time_download_series_data = time.time()\n",
        "    download_series_data_s5cmd(raw_base_path = raw_base_path, # --> ADD THIS TO GIT REPO. \n",
        "                               sorted_base_path = sorted_base_path,\n",
        "                               series_df = series_df,\n",
        "                               remove_raw = True)\n",
        "    elapsed_time_download_series_data = time.time()-start_time_download_series_data\n",
        "\n",
        "  # # DICOM CT to NIfTI - required for the processing\n",
        "  # start_time_ct_to_nii = time.time()\n",
        "  # preprocessing.pypla_dicom_ct_to_nifti(sorted_base_path = sorted_base_path,\n",
        "  #                                       processed_nifti_path = processed_nifti_path,\n",
        "  #                                       pat_id = series_id, \n",
        "  #                                       verbose = True)\n",
        "  # elapsed_time_ct_to_nii = time.time()-start_time_ct_to_nii \n",
        "\n",
        "  # DICOM CT to NifTI - required for processing \n",
        "  start_time_ct_to_nii = time.time()\n",
        "  success = dcm2niix_dicom_ct_to_nifti(sorted_base_path = sorted_base_path,\n",
        "                                       processed_nifti_path = processed_nifti_path,\n",
        "                                       pat_id = series_id)\n",
        "  elapsed_time_ct_to_nii = time.time()-start_time_ct_to_nii \n",
        "  if success == -1:\n",
        "    print(\"Cannot convert DICOM to NifTI using dcm2niix, either created no nii volumes or multiple volumes - stopping processing. \")\n",
        "    # create file in the log directory \n",
        "    dcm2nii_log_path = os.path.join(processed_base_path, 'dcm2nii_log.txt')\n",
        "    gs_uri_dcm2nii_log = os.path.join(bucket_log_folder_uri_nnunet, series_id + '_dcm2nii_log.txt')\n",
        "    with open(dcm2nii_log_path, 'w') as f:\n",
        "      f.write(\"Cannot convert DICOM to NifTI using dcm2niix, either created no nii volumes or multiple volumes - stopping processing. \")\n",
        "    f.close()\n",
        "    # !$s5cmd_path cp $dcm2nii_log_path $gs_uri_dcm2nii_log\n",
        "    !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $dcm2nii_log_path $gs_uri_dcm2nii_log\n",
        "    continue \n",
        "\n",
        "  # upload nifti file to bucket \n",
        "  ct_nifti_path = os.path.join(processed_nifti_path,series_id,series_id+\"_CT.nii.gz\")\n",
        "  !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $ct_nifti_path $gs_uri_ct_nifti_file\n",
        "\n",
        "\n",
        "  # prepare the `model_input` folder for the inference phase\n",
        "  preprocessing.prep_input_data(processed_nifti_path = processed_nifti_path,\n",
        "                                model_input_folder = model_input_folder_nnunet,\n",
        "                                pat_id = series_id)\n",
        "  \n",
        "  start_inference_nnunet = time.time()\n",
        "  # run the DL-based prediction\n",
        "  processing.process_patient_nnunet(model_input_folder = model_input_folder_nnunet,\n",
        "                                    model_output_folder = model_output_folder_nnunet, \n",
        "                                    nnunet_model = nnunet_model, \n",
        "                                    use_tta = use_tta,\n",
        "                                    export_prob_maps = export_prob_maps)\n",
        "  elapsed_inference_nnunet = time.time() - start_inference_nnunet\n",
        "\n",
        "  if export_prob_maps:\n",
        "    # convert the softmax predictions to NRRD files\n",
        "    postprocessing.numpy_to_nrrd(model_output_folder = model_output_folder_nnunet,\n",
        "                                processed_nrrd_path = processed_nrrd_path_nnunet,\n",
        "                                pat_id = series_id,\n",
        "                                output_folder_name = pred_softmax_folder_name)\n",
        "\n",
        "    # copy the nnU-Net *.npz softmax probabilities in the chosen bucket\n",
        "    !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $pred_softmax_folder_path/ $gs_uri_softmax_pred_folder/\n",
        "\n",
        "  # copy the nnU-Net *.nii.gz binary masks in the chosen bucket --> Do we need this? \n",
        "  # !gsutil -m cp $pred_nifti_path $gs_uri_nifti_file\n",
        "  !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $pred_nifti_path $gs_uri_nifti_file\n",
        "\n",
        "  # -----------------\n",
        "  # post-processing\n",
        "\n",
        "  # FIXME: consider removing this? (if only NIfTIs will be used to produce the DICOM SEGs)\n",
        "  # mandatory post-processing to convert the NIfTI file from the pipeline\n",
        "  # to a NRRD file (same content)\n",
        "  if not os.path.isdir(os.path.join(processed_nrrd_path_nnunet,series_id)):\n",
        "    os.mkdir(os.path.join(processed_nrrd_path_nnunet,series_id))\n",
        "  postprocessing.pypla_postprocess(processed_nrrd_path = processed_nrrd_path_nnunet,\n",
        "                                  model_output_folder = model_output_folder_nnunet,\n",
        "                                  pat_id = series_id)\n",
        "\n",
        "  # Modify the dicomseg_json file so that the SegmentAlgorithmName is representative of the model and other parameters \n",
        "  # Writes out the json file \n",
        "  SegmentAlgorithmName = experiment_folder_name \n",
        "  dicomseg_json_path_modified = \"/content/data/dicomseg_metadata_\" + SegmentAlgorithmName + '.json'\n",
        "  modify_dicomseg_json_file(dicomseg_json_path, dicomseg_json_path_modified, SegmentAlgorithmName)\n",
        "  # upload the json file \n",
        "  gs_uri_dicomseg_json_file = os.path.join(bucket_experiment_folder_uri_nnunet, 'dicomseg_metadata_' + SegmentAlgorithmName + '.json')\n",
        "  !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $dicomseg_json_path_modified $gs_uri_dicomseg_json_file\n",
        "\n",
        "  # -----------------\n",
        "  # extract features if nnunet_model is 3d and save structured report \n",
        "  if ('3d' in nnunet_model):\n",
        "    seg_dcm = pydicom.dcmread(pred_dicomseg_path)\n",
        "    SOPInstanceUID_seg = seg_dcm.file_meta['0x0002', '0x0003'].value\n",
        "    dcm_directory = os.path.join(sorted_base_path, series_id, 'CT')\n",
        "    nnunet_features_metajson = save_structured_report_for_shape_features(series_id, \n",
        "                                                                         SOPInstanceUID_seg, \n",
        "                                                                         pred_dicomseg_path,  \n",
        "                                                                         dicomseg_json_path, \n",
        "                                                                         dcm_directory,\n",
        "                                                                         pred_nifti_path, \n",
        "                                                                         nnunet_base_path, \n",
        "                                                                         ct_nifti_path, \n",
        "                                                                         nnunet_segments_code_mapping_df,\n",
        "                                                                         nnunet_shape_features_code_mapping_df,\n",
        "                                                                         sr_json_path,\n",
        "                                                                         sr_path\n",
        "                                                                         )\n",
        "    # Copy SR to bucket \n",
        "    !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $sr_path $gs_uri_sr_file"
      ],
      "metadata": {
        "id": "B1hg56TYdndS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RkKOcbyxs__u",
        "CZnoRi9Y7nEB",
        "VURToNwUW9Fm",
        "83S7J0xsyH_q",
        "rmAzW3AiN7nX",
        "_pVljPU1oOrO"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
