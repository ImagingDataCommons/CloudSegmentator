{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImagingDataCommons/CloudSegmentator/blob/v1.3.0/workflows/TotalSegmentator/Notebooks/inferenceTotalSegmentatorNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QhtMLIRPQsH"
      },
      "source": [
        "# **This Notebook performs inference using TotalSegmentator (v1.5.6) with CT NIfTI file as input and produces multilabel Segmentation Maps NIfTI file**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6wX5zMpPYn8"
      },
      "source": [
        "Please cite:\n",
        "\n",
        "Jakob Wasserthal, Manfred Meyer, Hanns-Christian Breit, Joshy Cyriac, Shan Yang, & Martin Segeroth. (2022). TotalSegmentator: robust segmentation of 104 anatomical structures in CT images. https://doi.org/10.48550/arXiv.2208.05868\n",
        "\n",
        "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nat Methods 18, 203–211 (2021). https://doi.org/10.1038/s41592-020-01008-z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toVsdH7JIV8H"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ImagingDataCommons/CloudSegmentator/v1.3.0/workflows/TotalSegmentator/Docs/images/inference.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umKIqpZcOMDp"
      },
      "source": [
        "Expected file directory\n",
        "```\n",
        "dcm2niix\n",
        " └─── $series_id_1\n",
        "       ├─── $CT_NIfTI.nii.gz\n",
        "       │\n",
        " └───  $series_id_2\n",
        "       ├─── $CT_NIfTI.nii.gz\n",
        "       ├───  ...\n",
        "       │\n",
        " └───  $series_id_n\n",
        "       └─── $CT_NIfTI.nii.gz\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99a_FPoOpH_I"
      },
      "source": [
        "### **Ways to utilize this notebook**\n",
        "\n",
        "\n",
        "*   **Colab**\n",
        "*   **DockerContainer/Terra/SB-CGC**\n",
        "\n",
        "\n",
        "#### **Colab**\n",
        "*  This notebook was initally developed and tested on Colab, and a working version is saved on github\n",
        "*  To run this notebook with Colab, Click 'Open In Colab' icon on top left\n",
        "*  A sample lz4 file is provided for convenience and can be downloaded when running the notebook in interactive mode\n",
        "*  Run each cell to install the packages and to run the inference using TotalSegmentator and the segmentation maps in NIfTI format are saved in lz4 compressed format\n",
        "\n",
        "\n",
        "#### **Docker**\n",
        "*  This notebook is primarly developed to be used on Terra/SB-CGC platforms using Docker\n",
        "*  Running this notebook in a docker container ensures reproduciblity, as we lock the run environment beginning from the base docker image to pip packages in the docker image\n",
        "*  Docker images can be found @ https://hub.docker.com/repository/docker/imagingdatacommons/inference_totalseg/tags\n",
        "*  The link to dockerfile along with git commit hash used for building the docker image can be found in one of the layers called 'LABEL'\n",
        "\n",
        "    <img src=\"https://raw.githubusercontent.com/ImagingDataCommons/CloudSegmentator/v1.3.0/workflows/TotalSegmentator/Docs/images/inference_docker.png\">\n",
        "\n",
        "* We use a python package called Papermill, that can run the notebook with out having to convert it to python script. This allows us maintain one copy of code instead of two.\n",
        "* A sample papermill command is\n",
        "    <pre>\n",
        "    papermill -p niftiFilePath path_to_ct_nifti_files.lz4 inferenceTotalSegmentatorNotebook.ipynb.ipynb  output_inferenceTotalSegmentatorNotebook.ipynb\n",
        "    </pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jcGevLmr3JW"
      },
      "source": [
        "### **Installing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0BAKG7AOI9a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !sudo apt-get update && apt-get install -y --no-install-recommends \\\n",
        "        build-essential\\\n",
        "        ffmpeg\\\n",
        "        lz4\\\n",
        "        python3-dev\\\n",
        "        python3-pip\\\n",
        "        wget\\\n",
        "        unzip\\\n",
        "        xvfb\\\n",
        "    && rm -rf /var/lib/apt/lists/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R68Zs8VTrvKg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install --no-cache-dir \\\n",
        "        ipykernel==6.22.0\\\n",
        "        ipython==8.12.0\\\n",
        "        ipywidgets==8.0.6\\\n",
        "        jupyter==1.0.0\\\n",
        "        papermill==2.4.0\\\n",
        "        nvidia-ml-py3==7.352.0\\\n",
        "        requests==2.27.1\\\n",
        "        TotalSegmentator==1.5.6\\\n",
        "    && pip install --no-cache-dir \\\n",
        "        pyradiomics==3.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nlRssXE5q5O"
      },
      "source": [
        "### **Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuihieSG5kjW"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import time\n",
        "import subprocess\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from time import sleep\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nvidia_smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Us8NmrKRBZ"
      },
      "source": [
        "### **Current Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdzaEz_5KXWz"
      },
      "outputs": [],
      "source": [
        "curr_dir   = Path().absolute()\n",
        "\n",
        "print(time.asctime(time.localtime()))\n",
        "print(\"\\nCurrent directory :{}\".format( curr_dir))\n",
        "print(\"Python version    :\", sys.version.split('\\n')[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhkrtpRH5MK1"
      },
      "source": [
        "### **For local testing**\n",
        "\n",
        "By default a sample manifest containing CT NIfTI files are chosen  here. However, you can modify them to your usecase.\n",
        "\n",
        "Below cell is also tagged as `parameters`, so that when running this notebook in non interactive mode on Terra or Seven Bridges Genomics- Cancer Genomics Cloud platforms, papermill will inject a cell to pass the path of the CT NIfTI files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3QXHGDp2htr",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if 'google.colab' in sys.modules:\n",
        "    !wget -q https://github.com/ImagingDataCommons/CloudSegmentator/releases/download/v1.0.0/downloadDicomAndConvertNiftiFiles.tar.lz4\n",
        "    niftiFilePath=glob.glob('*.lz4')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrD7DBKTJIHT"
      },
      "source": [
        "### **Decompressing NIFTI files from first step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_so3BoXMa10"
      },
      "outputs": [],
      "source": [
        "!lz4 -d --rm {niftiFilePath} -c | tar  --strip-components=0  -xvf -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGbSvle4RSpd"
      },
      "source": [
        "### **Defining Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqeESHc7ntX8"
      },
      "outputs": [],
      "source": [
        "#create directory for TotalSegmentator Output files\n",
        "try:\n",
        "  shutil.rmtree('Inference')\n",
        "\n",
        "except OSError:\n",
        "  pass\n",
        "os.mkdir('Inference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGQ_URr1pQpj"
      },
      "outputs": [],
      "source": [
        "class MemoryMonitor:\n",
        "    def __init__(self):\n",
        "        self.keep_measuring = True\n",
        "        self.working_disk_path = self.get_working_disk_path()\n",
        "\n",
        "    def get_working_disk_path(self):\n",
        "        partitions = psutil.disk_partitions()\n",
        "        for partition in partitions:\n",
        "            if partition.mountpoint == '/':\n",
        "                return '/'\n",
        "            elif '/cromwell_root' in partition.mountpoint:\n",
        "                return '/cromwell_root'\n",
        "        return '/'  # Default to root directory if no specific path is found\n",
        "    def measure_usage(self):\n",
        "        cpu_usage = []\n",
        "        ram_usage_mb=[]\n",
        "        gpu_usage_mb=[]\n",
        "        disk_usage_all=[]\n",
        "        time_stamps = []\n",
        "        start_time = time.time()\n",
        "        while self.keep_measuring:\n",
        "            cpu = psutil.cpu_percent()\n",
        "            ram = psutil.virtual_memory()\n",
        "            disk_usage = psutil.disk_usage(self.working_disk_path)\n",
        "            disk_used = disk_usage.used / 1000 / 1000 / 1000\n",
        "            disk_total = disk_usage.total / 1000 / 1000 / 1000\n",
        "            ram_total_mb = psutil.virtual_memory().total / 1000 / 1000\n",
        "            ram_mb = (ram.total - ram.available) / 1000 / 1000\n",
        "\n",
        "            try:\n",
        "                nvidia_smi.nvmlInit()\n",
        "                handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
        "                info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "                gpu_type = nvidia_smi.nvmlDeviceGetName(handle)\n",
        "                gpu_total_mb = info.total/1000/1000\n",
        "                gpu_mb = info.used/1000/1000\n",
        "                nvidia_smi.nvmlShutdown()\n",
        "            except:\n",
        "                gpu_type = ''\n",
        "                gpu_total_mb = 0\n",
        "                gpu_mb = 0\n",
        "\n",
        "            cpu_usage.append(cpu)\n",
        "            ram_usage_mb.append(ram_mb)\n",
        "            disk_usage_all.append(disk_used)\n",
        "            gpu_usage_mb.append(gpu_mb)\n",
        "            time_stamps.append(time.time()- start_time)\n",
        "            sleep(1)\n",
        "\n",
        "        return cpu_usage, ram_usage_mb, time_stamps, ram_total_mb, gpu_usage_mb, gpu_total_mb, gpu_type, disk_usage_all, disk_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXm-eEONAHMX"
      },
      "outputs": [],
      "source": [
        "def check_total_segmentator_errors(series_id: str):\n",
        "  \"\"\"\n",
        "  This function checks if the output files from TotalSegmentator exist.\n",
        "\n",
        "  Args:\n",
        "  series_id (str): The DICOM Tag SeriesInstanceUID of the DICOM series to be checked.\n",
        "\n",
        "  Returns:\n",
        "  bool: True if any of the output files do not exist, False otherwise.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define the output files from TotalSegmentator\n",
        "  output_files = [f\"Inference/{series_id}/segmentations.nii\"]\n",
        "\n",
        "  # Check if all output files exist\n",
        "  if not all(os.path.exists(file) for file in output_files):\n",
        "      # If any of the output files do not exist, log an error\n",
        "      with open('totalsegmentator_errors.txt', 'a') as f:\n",
        "          f.write(f\"Error: TotalSegmentator failed for series {series_id}\\n\")\n",
        "      return True\n",
        "\n",
        "  return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10_jVVTElNZ5"
      },
      "outputs": [],
      "source": [
        "def inferenceTotalSegmentator(series_id: str, runtime_stats: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function performs inference using TotalSegmentator on a given series.\n",
        "\n",
        "    Args:\n",
        "    series_id (str): The DICOM Tag SeriesInstanceUID of the DICOM series to be processed.\n",
        "    runtime_stats: DataFrame to store runtime statistics.\n",
        "\n",
        "    Returns:\n",
        "    Updated DataFrame with runtime statistics.\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove existing directories and files if they exist\n",
        "    shutil.rmtree(f\"Inference/{series_id}\", ignore_errors=True)\n",
        "    shutil.rmtree(f\"metadata/{series_id}\", ignore_errors=True)\n",
        "    for file in [\"segmentations.nii.gz\"]:\n",
        "        try:\n",
        "            os.remove(file)\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "    # Create a new directory for the series\n",
        "    os.makedirs(f\"Inference/{series_id}\", exist_ok=True)\n",
        "\n",
        "    print(f\"Processing series: {series_id}\")\n",
        "\n",
        "    log = pd.DataFrame({\"SeriesInstanceUID\": [series_id]})\n",
        "    series_id_folder_path = os.path.join(\"dcm2niix\", series_id)\n",
        "\n",
        "    # Get the first (and only) file in the list\n",
        "    nifti_filename = os.listdir(series_id_folder_path)[0]\n",
        "    nifti_filename_path = os.path.join(series_id_folder_path, nifti_filename)\n",
        "\n",
        "    start_time = time.time()\n",
        "    result = subprocess.run(\n",
        "        [\"TotalSegmentator\", \"-i\", nifti_filename_path, \"-o\", \"segmentations\", \"--ml\"],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    print(result.stdout)\n",
        "    total_segmentator_time = time.time() - start_time\n",
        "\n",
        "    # Move the output files to the appropriate directory\n",
        "    try:\n",
        "        shutil.move(f\"segmentations.nii\", f\"Inference/{series_id}/\")\n",
        "        print(\"Files moved successfully using the first command\")\n",
        "    except FileNotFoundError:\n",
        "        try:\n",
        "            shutil.move(\"segmentations/segmentations.nii\", f\"Inference/{series_id}/\")\n",
        "            print(\"Files moved successfully using the second command\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"Error: Failed to move files using both commands\")\n",
        "\n",
        "    check_total_segmentator_errors(series_id)\n",
        "\n",
        "    shutil.move(\n",
        "        f\"Inference/{series_id}/segmentations.nii\",\n",
        "        f\"Inference/{series_id}/{series_id}.nii\",\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    subprocess.run(\n",
        "        [\n",
        "            \"lz4\",\n",
        "            \"--rm\",\n",
        "            f\"Inference/{series_id}/{series_id}.nii\",\n",
        "            f\"Inference/{series_id}/{series_id}.nii.lz4\",\n",
        "        ],\n",
        "        check=True,\n",
        "    )\n",
        "\n",
        "    archiving_time = time.time() - start_time\n",
        "\n",
        "    log[\"total_segmentator_time\"] = total_segmentator_time\n",
        "    log[\"archiving_time\"] = archiving_time\n",
        "\n",
        "    shutil.rmtree(f\"dcm2niix/{series_id}\", ignore_errors=True)\n",
        "\n",
        "\n",
        "    runtime_stats = pd.concat([runtime_stats, log], ignore_index=True, axis=0)\n",
        "\n",
        "    return runtime_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_L2B-sjRf_1"
      },
      "source": [
        "### **Total Segmentator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZfAhcQopl59"
      },
      "outputs": [],
      "source": [
        "runtime_stats = pd.DataFrame(columns=['SeriesInstanceUID','total_segmentator_time',\n",
        "                                      'archiving_time', 'cpu_usage','ram_usage_mb', 'ram_total_mb',\n",
        "                                      'gpu_usage_mb', 'gpu_total_mb', 'gpu_type', 'disk_usage_all', 'disk_total'\n",
        "                                      ])\n",
        "if __name__ == \"__main__\":\n",
        "    for series_id in os.listdir('dcm2niix'):\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            monitor = MemoryMonitor()\n",
        "            mem_thread = executor.submit(monitor.measure_usage)\n",
        "            try:\n",
        "                proc_thread = executor.submit(inferenceTotalSegmentator, series_id, runtime_stats)\n",
        "                runtime_stats = proc_thread.result()\n",
        "            finally:\n",
        "                monitor.keep_measuring = False\n",
        "                cpu_usage, ram_usage_mb, time_stamps, ram_total_mb, gpu_usage_mb, gpu_total_mb, gpu_type, disk_usage_all, disk_total= mem_thread.result()\n",
        "\n",
        "                cpu_idx = runtime_stats.index[runtime_stats['SeriesInstanceUID'] == series_id][0]\n",
        "                runtime_stats.iloc[cpu_idx, runtime_stats.columns.get_loc('cpu_usage')] = [[cpu_usage]]\n",
        "\n",
        "                ram_usage_mb_idx = runtime_stats.index[runtime_stats['SeriesInstanceUID'] == series_id][0]\n",
        "                runtime_stats.iloc[ram_usage_mb_idx, runtime_stats.columns.get_loc('ram_usage_mb')] = [[ram_usage_mb]]\n",
        "\n",
        "                ram_total_mb_idx = runtime_stats.index[runtime_stats['SeriesInstanceUID'] == series_id][0]\n",
        "                runtime_stats.iloc[ram_total_mb_idx, runtime_stats.columns.get_loc('ram_total_mb')] = [[ram_total_mb]]\n",
        "\n",
        "                gpu_total_mb_idx = runtime_stats.index[runtime_stats['SeriesInstanceUID'] == series_id][0]\n",
        "                runtime_stats.iloc[gpu_total_mb_idx, runtime_stats.columns.get_loc('gpu_total_mb')] = [[gpu_total_mb]]\n",
        "\n",
        "                gpu_usage_mb_idx = runtime_stats.index[runtime_stats['SeriesInstanceUID'] == series_id][0]\n",
        "                runtime_stats.iloc[gpu_usage_mb_idx, runtime_stats.columns.get_loc('gpu_usage_mb')] = [[gpu_usage_mb]]\n",
        "\n",
        "                disk_usage_gb_idx = runtime_stats.index[runtime_stats['SeriesInstanceUID'] == series_id][0]\n",
        "                runtime_stats.iloc[disk_usage_gb_idx, runtime_stats.columns.get_loc('disk_usage_all')] = [[disk_usage_all]]\n",
        "\n",
        "                runtime_stats['gpu_type']=gpu_type\n",
        "                runtime_stats['disk_total']=disk_total\n",
        "\n",
        "                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(8, 6))\n",
        "\n",
        "                ax1.plot(time_stamps, cpu_usage)\n",
        "                ax1.set_ylim(0, 100)\n",
        "                ax1.set_xlabel('Time (s)')\n",
        "                ax1.set_ylabel('CPU usage (%)')\n",
        "\n",
        "                ax2.plot(time_stamps, ram_usage_mb)\n",
        "                ax2.set_ylim(0, ram_total_mb)\n",
        "                ax2.set_xlabel('Time (s)')\n",
        "                ax2.set_ylabel('Memory usage (MB)')\n",
        "\n",
        "                ax3.plot(time_stamps, gpu_usage_mb)\n",
        "                ax3.set_ylim(0, gpu_total_mb)\n",
        "                ax3.set_xlabel('Time (s)')\n",
        "                ax3.set_ylabel('GPU Memory usage (MB)')\n",
        "\n",
        "                ax4.plot(time_stamps, disk_usage_all)\n",
        "                ax4.set_ylim(0, disk_total)\n",
        "                ax4.set_xlabel('Time (s)')\n",
        "                ax4.set_ylabel('Disk usage (GB)')\n",
        "                plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzCG2YATRtVH"
      },
      "source": [
        "### **Compressing Output Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxuuD6yqdmzF"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "try:\n",
        "  os.remove('inferenceNiftiFiles.tar.lz4')\n",
        "  #os.remove('metadata.tar.lz4')\n",
        "except OSError:\n",
        "  pass\n",
        "!tar cvf - -C {curr_dir} Inference | lz4 > inferenceNiftiFiles.tar.lz4\n",
        "archiving_time = time.time() - start_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4pMpClKRzEe"
      },
      "source": [
        "### **Utilization Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc7Hep0lkJWd"
      },
      "outputs": [],
      "source": [
        "runtime_stats.to_csv('runtime.csv')\n",
        "runtime_stats['archiving_time']=archiving_time\n",
        "try:\n",
        "  os.remove('inferenceUsageMetrics.lz4')\n",
        "except OSError:\n",
        "  pass\n",
        "!lz4 runtime.csv inferenceUsageMetrics.lz4\n",
        "runtime_stats"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Tags",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
