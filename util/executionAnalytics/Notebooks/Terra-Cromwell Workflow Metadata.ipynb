{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImagingDataCommons/CloudSegmentator/blob/v1.1.0/util/executionAnalytics/Notebooks/Terra-Cromwell%20Workflow%20Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOm9jKxwxNmG"
      },
      "source": [
        "# An introduction to using the Fiss API in Python in BioData Catalyst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twUUAjLOxNmK"
      },
      "source": [
        "This notebook introduces users to the Firecloud API using a Python Jupyter notebook. The example covers how the API communicates between the data table and notebook. The user loads an existing Terra data table into the notebook, subsets the dataframe, and saves the new dataframe as a tsv to the workspace bucket or as a new Terra data table.\n",
        "\n",
        "Note: a more scalable version of this process is available in the [terra_data_table_util](https://app.terra.bio/#workspaces/biodata-catalyst/BioData%20Catalyst%20Collection/notebooks/launch/terra_data_table_util.ipynb) notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR0nP6iGxNmL"
      },
      "source": [
        "## Notebook Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uac-J4_DxNmM"
      },
      "source": [
        "We suggest using both the default environment and compute power. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0vQqGoyxhWT"
      },
      "source": [
        "###**Installing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUWS2Tu-xfD4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install firecloud "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyBZmepd5DQQ",
        "outputId": "aaf9939a-6d62-4a83-8832-9bff53cc4827"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHaXydC9xNmM"
      },
      "source": [
        "# Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UUz2NNyxNmN"
      },
      "outputs": [],
      "source": [
        "from firecloud import fiss\n",
        "import firecloud.api as fapi\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ydK18COeCCX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "credentials_file = '/content/drive/MyDrive/idc/application_default_credentials.json'\n",
        "# Set the environment variable\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_file\n",
        "\n",
        "# Your code goes here\n",
        "# Perform the authentication and access the necessary resources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IZCzSDzxNmO"
      },
      "source": [
        "## Set environment variables that Fiss API requires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53f15epLxNmP",
        "outputId": "2f4815ae-5bab-4b9b-b9a2-6a5aa0ac5e25"
      },
      "outputs": [],
      "source": [
        "# Get the Google billing project name and workspace name\n",
        "#billing_project = os.environ['WORKSPACE_NAMESPACE']\n",
        "#workspace = os.environ['WORKSPACE_NAME']\n",
        "#bucket = os.environ['WORKSPACE_BUCKET'] + \"/\"\n",
        "\n",
        "billing_project= 'terra-billing-datester'\n",
        "workspace= 'TotalSegmentator'\n",
        "bucket= 'gs://fc-5af492dc-6993-4c91-bbf6-3e2747868642/'\n",
        "\n",
        "\n",
        "# Verify that we've captured the environment variables\n",
        "print(\"Billing project: \" + billing_project)\n",
        "print(\"Workspace: \" + workspace)\n",
        "print(\"Workspace storage bucket: \" + bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bnyqTDRxNmQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def get_workflow_metadata_with_retry(billing_project, workspace, submission_id, workflow_id):\n",
        "    max_attempts = 3\n",
        "    print(f'Getting workflow metadata for workflow {workflow_id} in submission {submission_id}...')\n",
        "    for i in range(max_attempts):\n",
        "        print(f'Attempt {i+1} of {max_attempts}...')\n",
        "        response = fiss.fapi.get_workflow_metadata(billing_project, workspace, submission_id, workflow_id)\n",
        "        if response.status_code >= 200 and response.status_code < 300:\n",
        "            print(f'Successfully retrieved workflow metadata for workflow {workflow_id} in submission {submission_id}.')\n",
        "            return response\n",
        "        else:\n",
        "            print(f'Received response with status code {response.status_code}. Retrying after 30 seconds...')\n",
        "            time.sleep(30)\n",
        "    raise Exception(f'Failed to get workflow metadata for workflow {workflow_id} after {max_attempts} attempts')\n",
        "\n",
        "\n",
        "def get_submission_with_retry(billing_project, workspace, submission_id):\n",
        "    max_attempts = 3\n",
        "    print(f'Getting submission {submission_id}...')\n",
        "    for i in range(max_attempts):\n",
        "        print(f'Attempt {i+1} of {max_attempts}...')\n",
        "        response = fapi.get_submission(billing_project, workspace, submission_id)\n",
        "        if response.status_code >= 200 and response.status_code < 300:\n",
        "            print(f'Successfully retrieved submission {submission_id}.')\n",
        "            return response\n",
        "        else:\n",
        "            print(f'Received response with status code {response.status_code}. Retrying after 30 seconds...')\n",
        "            time.sleep(30)\n",
        "    raise Exception(f'Failed to get submission {submission_id} after {max_attempts} attempts')\n",
        "    \n",
        "    \n",
        "def list_submissions_with_retry(billing_project, workspace):\n",
        "    max_attempts = 3\n",
        "    print(f'Listing submissions for workspace {workspace} in billing project {billing_project}...')\n",
        "    for i in range(max_attempts):\n",
        "        print(f'Attempt {i+1} of {max_attempts}...')\n",
        "        response = fapi.list_submissions(billing_project, workspace)\n",
        "        if response.status_code >= 200 and response.status_code < 300:\n",
        "            print(f'Successfully retrieved list of submissions for workspace {workspace} in billing project {billing_project}.')\n",
        "            return response\n",
        "        else:\n",
        "            print(f'Received response with status code {response.status_code}. Retrying after 30 seconds...')\n",
        "            time.sleep(30)\n",
        "    raise Exception(f'Failed to list submissions for workspace {workspace} in billing project {billing_project} after {max_attempts} attempts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tu-p6GHzxNmR",
        "outputId": "5e01f169-a028-4288-a02c-1a20258a03e6"
      },
      "outputs": [],
      "source": [
        "submissions_list_response=list_submissions_with_retry(billing_project, workspace)\n",
        "submissions_list=submissions_list_response.json()\n",
        "submissions_list = [submission['submissionId'] for submission in submissions_list]\n",
        "submissions_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SzR9_hF5xNmS",
        "outputId": "abf818fa-1eaf-4e0a-87f4-dc63e34787ee"
      },
      "outputs": [],
      "source": [
        "columns = ['attempt', 'backend', 'cromwell-workflow-id', 'terra-submission-id', 'wdl-task-name', 'compressedDockerSize', 'dockerImageUsed', 'end', 'start', 'executionStatus', 'executionBucket', 'googleProject', 'instanceName', 'machineType', 'zone', 'runtimeAttributes', 'description', 'startTime', 'endTime']\n",
        "final = pd.DataFrame(columns=columns)\n",
        "\n",
        "for submission in submissions_list:\n",
        "    submissions_response= get_submission_with_retry(billing_project, workspace, submission)\n",
        "    workflows = submissions_response.json()['workflows']\n",
        "    #workflows_ids = [workflow['workflowId'] for workflow in workflows]\n",
        "    workflows_ids = []\n",
        "    for workflow in workflows:\n",
        "        if 'workflowId' in workflow:\n",
        "            workflows_ids.append(workflow['workflowId'])\n",
        "    for workflow in workflows_ids:\n",
        "        workflow_response = get_workflow_metadata_with_retry(billing_project, workspace, submission, workflow)\n",
        "        workflow_data = workflow_response.json()\n",
        "        if 'calls' in workflow_data:\n",
        "            keys = workflow_data['calls'].keys()\n",
        "            dataframes = {}\n",
        "            for key in keys:\n",
        "                attempts = workflow_data['calls'][key]\n",
        "                df = pd.DataFrame(columns=columns)\n",
        "                rows = []\n",
        "                for attempt in attempts:\n",
        "                    for event in attempt['executionEvents']:\n",
        "                        if 'backendLabels' in attempt:\n",
        "            # Extract the information we need\n",
        "                            row = {\n",
        "                                'attempt': attempt['attempt'],\n",
        "                                'backend': attempt['backend'],\n",
        "                                'cromwell-workflow-id': attempt['backendLabels']['cromwell-workflow-id'],\n",
        "                                'terra-submission-id': attempt['backendLabels']['terra-submission-id'],\n",
        "                                'wdl-task-name': attempt['backendLabels']['wdl-task-name'],\n",
        "                                'compressedDockerSize': float(attempt.get('compressedDockerSize', 0))/1073741824,\n",
        "                                'dockerImageUsed': attempt.get('dockerImageUsed', 'default_value'),\n",
        "                                'end': attempt['end'],\n",
        "                                'start': attempt['start'],\n",
        "                                'executionStatus': attempt['executionStatus'],\n",
        "                                'failures': attempt.get('failures','default'),\n",
        "                                'executionBucket': attempt['jes']['executionBucket'],\n",
        "                                'googleProject': attempt['jes']['googleProject'],\n",
        "                                'instanceName': attempt['jes']['instanceName'],\n",
        "                                'machineType': attempt['jes']['machineType'],\n",
        "                                'zone': attempt['jes']['zone'],\n",
        "                                'runtimeAttributes': attempt['runtimeAttributes'],\n",
        "                                'description': event['description'],\n",
        "                                'startTime': event['startTime'],\n",
        "                                'endTime': event['endTime']\n",
        "                            }\n",
        "                            rows.append(row)\n",
        "                df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)\n",
        "                dataframes[key] = df\n",
        "            final = pd.concat([final, pd.concat(dataframes.values(), ignore_index=True)], ignore_index=True)\n",
        "final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9osQ4Xw8xNmT"
      },
      "outputs": [],
      "source": [
        "final.to_csv('data.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
